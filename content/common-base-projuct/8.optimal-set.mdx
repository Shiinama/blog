# 项目整体优化

这一章是中间章，因为已经快达成广告站的要素了，就综合优化一下整个模版以及基础功能。

## AI批量生成内容的架构改造

在项目中，我们需要实现AI批量生成内容的功能，但在Cloudflare的生产环境是有问题的。由于Cloudflare的serverless架构存在执行时间限制，长时间运行的批量生成任务无法直接在单个请求中完成。

我浪费了几乎一天，去尝试了四种解决方案。

https://demo.getwhynot.org/, 目前首页保留了4个可以控制时间，调用同一个actions的测试，可以发现：

- Next.js对并发Server Actions请求进行了优化，导致请求被强行串行化处理
- 长时间任务会导致请求直接失败

![](https://ik.imagekit.io/ixou4q6nu/issue-cloudflare.png)

### 1. Cloudflare队列（Queue）方案

这种方案在我最开始的设想中应该是合适的，利用Cloudflare提供的队列服务来管理批量任务。思路是创建一个队列，将每个生成任务作为消息推送到队列中，设置消费者来处理队列中的任务。

**遇到的问题**：因为Worker类型的问题，无法通过内部事件通知或端口监听方式自动触发任务处理，缺乏队列任务完成的实时通知机制，导致我要通过外部HTTP请求轮询队列来获取和处理任务。

> 这不如直接把我杀了把，没有内部消费通知机制，我要队列干嘛？

### 2. Cloudflare waitUntil API方案

这种方案是使用Cloudflare提供的`waitUntil`API来延长任务执行时间。

**技术点**：

- `waitUntil`允许在HTTP响应返回后继续执行后台任务
- 可以在请求处理函数中注册异步任务

**遇到的问题**：

- `waitUntil`仍然有执行时间上限（约30秒）
- 只能在请求上下文中使用，无法跨请求持久化任务
- 不适合需要长时间运行的批量生成任务

**结论**：这种方案只能延长单个请求的执行时间，无法真正解决批量任务的问题。

### 3. 前端 + Server Actions方案

从这里开始，我就想：把批量生成的实现放在客户端把（即使非常的恶心，最佳实践这种一定是在服务端，因为客户端关闭任务就断了）。

所以我就利用Next.js的Server Actions在前端发起并控制批量任务，在前端将批量任务拆分为多个小任务，使用Server Actions并发调用后端API。

**遇到的问题**：

- 发现Next.js对并发Server Actions请求进行了优化，导致请求被强行串行化处理
- 无法实现真正的并发执行，影响批量生成效率

由于框架的内部优化机制，这种方案无法实现预期的并发效果。

### 4. 前端 + API Routes控制方案

没有办法，换种思路，把Actions换成API Routers，绕过Server Actions在单客户端的并发限制，最终成功。

Route API的实现在`app/api/generate-article/route.ts`

```typescript
import { NextRequest, NextResponse } from 'next/server'

import { generateArticle } from '@/actions/ai-content'
import { auth } from '@/lib/auth'

export const runtime = 'edge'

interface RequestBody {
  keyword: string
  locale?: string
}

export async function POST(request: NextRequest) {
  const u = await auth()
  if (u?.user?.id !== process.env.NEXT_PUBLIC_ADMIN_ID) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
  }
  try {
    const body: RequestBody = await request.json()
    const { keyword, locale } = body

    if (!keyword) {
      return NextResponse.json({ error: 'Keyword is required' }, { status: 400 })
    }

    const article = await generateArticle({ keyword, locale })
    return NextResponse.json(article)
  } catch (error: any) {
    console.error('Error generating article:', error)
    return NextResponse.json({ error: error.message || 'Failed to generate article' }, { status: 500 })
  }
}
```

并发的核心实现在`app/[locale]/admin/articles/batch/page.tsx 53行开始`

```typescript
try {
  for (let i = 0; i < keywords.length; i += batchSize) {
    const batch = keywords.slice(i, i + batchSize)
    const batchPromises = batch.map(async (keyword) => {
      const response = await fetch('/api/generate-article', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({ keyword, locale: selectedLocale })
      })

      if (!response.ok) {
        const errorData = await response.json()
        return {
          keyword,
          error: errorData,
          status: 'error'
        }
      }

      const article = await response.json()
      return {
        keyword,
        article,
        status: 'success'
      }
    })

    const batchResults = []
    for (const promise of batchPromises) {
      try {
        const result = await promise
        batchResults.push(result)
      } catch (error) {
        batchResults.push({
          status: 'error',
          error: error instanceof Error ? error.message : 'Unknown error'
        })
      }
    }
    results.push(...batchResults)
  }

  const articlesWithSelection = results.map((item) => ({
    ...item,
    selected: item.status === 'success'
  }))

  setGeneratedArticles(articlesWithSelection)

  const successCount = results.filter((a) => a.status === 'success').length
  const errorCount = results.filter((a) => a.status === 'error').length

  toast.success(
    t('success.generated', {
      successCount: String(successCount),
      errorMessage: errorCount > 0 ? t('success.withErrors', { errorCount: String(errorCount) }) : ''
    })
  )
} catch (error) {
  console.error('Error generating articles:', error)
  toast.error(t('errors.generateFailed'))
} finally {
  setIsGenerating(false)
}
```

到这就可以在线上管理和生成内容了。

## 分页实现

后端分页的实现，就是前端传入当前页面和数量，返回结果和数量即可。

```typescript
export async function getPaginatedArticles({
  locale,
  page = 1,
  pageSize = 10
}: {
  locale?: string
  page?: number
  pageSize?: number
}) {
  const database = createDb()

  const currentPage = Math.max(1, page)
  const itemsPerPage = Math.max(1, pageSize)
  const offset = (currentPage - 1) * itemsPerPage

  const baseQuery = database.select().from(posts).orderBy(desc(posts.publishedAt))

  const query = locale ? baseQuery.where(eq(posts.locale, locale)) : baseQuery

  const countQuery = locale
    ? database.select({ count: count() }).from(posts).where(eq(posts.locale, locale))
    : database.select({ count: count() }).from(posts)

  const [articles, countResult] = await Promise.all([query.limit(itemsPerPage).offset(offset), countQuery])

  const totalItems = countResult[0]?.count || 0
  const totalPages = Math.ceil(totalItems / itemsPerPage)

  return {
    articles,
    pagination: {
      currentPage,
      pageSize: itemsPerPage,
      totalItems,
      totalPages
    }
  }
}
```

而前端的分页器实现需要注意的是，前进后退以及页面的点击需要是链接，因为是要给爬虫去爬的~

```typescript
const PaginationLink = ({ className, isActive, size = 'icon', ...props }: PaginationLinkProps) => (
  <Link
    aria-current={isActive ? 'page' : undefined}
    className={cn(
      buttonVariants({
        variant: isActive ? 'outline' : 'ghost',
        size
      }),
      className
    )}
    {...props}
  />
)
PaginationLink.displayName = 'PaginationLink'


{pageNumbers.map((page, index) => {
  if (page === 'ellipsis-start' || page === 'ellipsis-end') {
    return (
      <PaginationItem key={`ellipsis-${index}`}>
        <PaginationEllipsis />
      </PaginationItem>
    )
  }

  return (
    <PaginationItem key={page}>
      <PaginationLink href={createPageURL(page as number)} isActive={page === currentPage}>
        {page}
      </PaginationLink>
    </PaginationItem>
  )
})}
```

## 完善AI的能力接入更强的模型API

实际上决定AI应用上限的因素之一是模型的强度。我们可以通过查看 [OpenRouter榜单](https://openrouter.ai/rankings/roleplay?view=week) 来帮助我们快速选择场景适合的模型，而在我们的代码层要实现的事情就是尽可能的覆盖市面的模型和场景。

下面提到的例子是我最常用的，类型和生态完整的库，我们没必要进一步封装了，就直接调用库方法就好。

> 但我没把OpenRouter和OpenAI写在代码中，因为我们要始终保持一个理念：`在盈利之前，不要花钱投入，用最小的杠杆去撬动收益`（主要还是因为大家都不富裕，有条件的直接上就是了）。这也是我在社群中经常会发各种免费的API额度和各种厂商的credit的核心原因。

### Cloudflare生态AI

每日都有刷新的免费额度，好的模型很少，但胜在覆盖多模态、无成本。

![](https://ik.imagekit.io/ixou4q6nu/cloudflare-models.png)

用法都是通过`ai run`的方法，传入系列模型参数，模型名字，返回不同的值，地址在：https://demo.getwhynot.org/image-generator：

```typescript
'use server'

import { createAI } from '@/lib/ai'

export async function cloudflareTextToImage(prompt: string) {
  try {
    const ai = createAI()
    const response = await ai.run('@cf/black-forest-labs/flux-1-schnell', {
      prompt: prompt
    })

    const base64Image = response.image?.startsWith('data:image/')
      ? response.image
      : `data:image/png;base64,${response.image}`

    return {
      success: true,
      imageData: base64Image,
      error: null
    }
  } catch (error) {
    console.error('Error generating image:', error)
    return {
      success: false,
      imageData: null,
      error: error instanceof Error ? error.message : 'Unknown error occurred'
    }
  }
}
```

### OpenRouter

[OpenRouter](https://openrouter.ai/)是最大且比较正规的代理商，可以选择市面上所有的主流模型，但只有文字场景以及有成本。

先`pnpm add @openrouter/ai-sdk-provider ai`，一个是`vecel`的`ai库`帮助你处理流式输出，重试等情况，一个是`openrouter`帮助你绑定大模型，下图代码是流式返回的示例。(这部分代码是在：https://github.com/Shiinama/easy-business-ai)

```typescript
import { createOpenRouter } from '@openrouter/ai-sdk-provider'

const openrouter = createOpenRouter({
  apiKey: OPEN_ROUTER_API_KEY
})

const systemMessage = { role: MessageRole.assistant, content: chatSettings.systemPrompt }
const historyMessages = (session?.messages ?? []).map((i) => ({ ...i, role: i.role }))
const userMessage = { role: MessageRole.user, content: message }

const response = streamText({
  model: openrouter(chatSettings.model),
  messages: [systemMessage, ...historyMessages, userMessage],
  maxTokens: chatSettings.maxTokens,
  temperature: chatSettings.temperature,
  topP: chatSettings.topP,
  frequencyPenalty: chatSettings.frequencyPenalty,
  presencePenalty: chatSettings.presencePenalty,
  maxRetries: 3
})

for await (const textPart of response.textStream) {
  str += textPart
  requestAnimationFrame(() => {
    appendMessage(
      {
        id: assistantId,
        role: MessageRole.assistant,
        content: textPart
      },
      conversationId
    )
  })
}

const usage = await response.usage

const assistantTokenCount = usage.completionTokens
```

### OpenAI生态

OpenAI的主要缺点是价格相对较高，以及在某些地区的访问限制，但总有办法的~（有非常多盗刷信用卡的灰产渠道和代理商，价格很低）。它的好处也很多，Openai的模型是自带流量的，效果尚可，并且它们家老是炒作营销事件，很容易跟风。

集成OpenAI API非常简单，首先安装依赖：

```bash
pnpm add openai ai
```

以下是使用GPT-4o模型的简洁示例：

```typescript
'use server'

import OpenAI from 'openai'
import { OpenAIStream, StreamingTextResponse } from 'ai'

// 创建OpenAI客户端实例
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

export async function chatWithAI(messages: any[]) {
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages,
      temperature: 0.7,
      stream: true
    })

    // 使用Vercel AI SDK处理流式响应
    return new StreamingTextResponse(OpenAIStream(response))
  } catch (error) {
    console.error('OpenAI API error:', error)
    throw new Error('AI服务暂时不可用')
  }
}
```

多模态，例如处理图像和文本的结合：

```typescript
'use server'

import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

export async function analyzeImage(imageUrl: string, prompt: string) {
  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [
      {
        role: 'user',
        content: [
          { type: 'text', text: prompt },
          { type: 'image_url', image_url: { url: imageUrl } }
        ]
      }
    ]
  })

  return response.choices[0].message.content
}
```

### Gmi

这个是免费领API额度的平台，它是个卖Gpu的，通过我给的兑换码，送100$。

![](https://ik.imagekit.io/ixou4q6nu/gmi-models.png)

兑换码兑换后，添加一个api key。

![](https://ik.imagekit.io/ixou4q6nu/add-key-gmi.png)

添加一个环境变量`GMI_API_KEY`在env，就这样Api就完成了，前端就不讲了，路由在`https://demo.getwhynot.org/deepseek-prover`。

```typescript
'use server'

interface DeepSeekMessage {
  role: string
  content: string
}

interface DeepSeekChoice {
  message: DeepSeekMessage
  index?: number
  finish_reason?: string
}

interface DeepSeekUsage {
  prompt_tokens: number
  completion_tokens: number
  total_tokens: number
}

interface DeepSeekResponse {
  id: string
  object: string
  created: number
  model: string
  choices: DeepSeekChoice[]
  usage: DeepSeekUsage
}

export async function generateDeepSeekResponse(prompt: string): Promise<DeepSeekResponse> {
  if (!prompt.trim()) {
    throw new Error('Prompt is required')
  }

  try {
    const response = await fetch('https://api.gmi-serving.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${process.env.GMI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'deepseek-ai/DeepSeek-Prover-V2-671B',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0,
        max_tokens: 12000
      })
    })

    if (!response.ok) {
      const error = await response.json()
      throw new Error(`DeepSeek API error: ${JSON.stringify(error)}`)
    }

    const data: DeepSeekResponse = await response.json()
    return data
  } catch (error) {
    console.error('Error calling DeepSeek API:', error)
    throw new Error(error instanceof Error ? error.message : 'Failed to process request')
  }
}
```

## 完成Footer和Header

请先参考这篇[文章](https://articles.zsxq.com/id_c3m5cx40if2n.html)，这是在遵循这个实践，把`header`和`footer`的内页计算权重在固定下来，并完成一个能提供很多版面又不会让用户厌烦的UI。

```
<Header />
  <main className="mx-auto flex w-full max-w-(--breakpoint-xl) flex-1 flex-col px-2.5 py-8 md:px-20">
    {children}
  </main>
<Footer />
```

实际上更复杂的产品/大站会通过面包屑、轮播图、相关链接等方式去控制更细节的权重流向。

## 杂项

### 添加Viewport

```typescript
export const viewport: Viewport = {
  width: 'device-width',
  initialScale: 1,
  maximumScale: 1,
  userScalable: false
}
```

### 品牌名继承

你可以在 `layout.tsx` 文件中使用 `title.template` 属性来为所有页面添加品牌名：

```typescript
title: {
  default: t('meta.title'),
  template: `%s | ${t('brandName')}`
},
```

这样，当子页面设置自己的标题时，会自动应用模板，在标题后添加品牌名。如果页面没有设置标题，则使用默认标题。

> 在每个页面标题中包含品牌名（如"页面标题 | 品牌名"）可以增强品牌一致性，帮助用户在搜索结果中识别出你的网站，提高品牌知名度~

### I18n Cli最常用用法

- **i18n:delete**: `pnpm i18n:delete "key,object.key"`，会删除所有翻译文件中的Key，因为我们经常会写错，这是一个简便的方法。
- **i18n:keys**: `pnpm i18n:keys "key,object.key"`，会替换翻译key以当前的选定语言为标准（默认en）。
- **i18n:sequential**: `pnpm i18n:sequential`，分批跑在各文件缺少的key，解决上下文超限的问题（默认每批3个key，可以动态调整，文件是`scripts/18n/sequential-translate.ts`）。

### 完善I18n固定板块

折叠的部分是在已经不用改变的，可以直接固定，而后续需要改变的部分则是：

1. headers后续添加导航的时候需要跑一下`pnpm i18n:sequential`。
2. siteInfo的部分，大家针对自己的业务和品牌（让AI生或者中文）修改后，跑`pnpm i18n:keys "siteInfo"`。
3. footer与第二点同理。
4. home page是主业务，在完成所有的业务和文案后`pnpm i18n:sequential`。

![](https://ik.imagekit.io/ixou4q6nu/template-18n-en.png)

这就是集中式文案的好处，其实整个部分都是通过AI可以生成的，并且保持了自由度和可以通过脚本调整。

## 结束

[本章Tag](https://github.com/Shiinama/next-cloudflare-template/tree/v6.1.1)，大家可以看看还有什么是需要添加和优化的，这一章会继续补充。
